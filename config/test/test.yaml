model:
  _target_: ezspeech.inference_models.tdt_inference.LightningASR
  filepath: hehe.ckpt
  device: cuda
  vocab: /data/khanhnd65/Ezspeech/ezspeech/resource/vocab.txt
  decoding_cfg:
    # Using greedy decoding is highly recommended for TDT models. Using greedy-batch will give very bad results
    # if omega is 0; even if omega is non-zero, greedy-batch results are still going to be inaccurate.
    strategy: "greedy"
    model_type: "tdt"
    # this must not be None in order to use the TDT specific decoding method.
    durations: [0,1,2,3,4]
    # greedy strategy config
    greedy:
      max_symbols: 10
    # beam strategy config
    beam:
      beam_size: 2
      return_best_hypothesis: False
      score_norm: true
      alsd_max_target_len: 2.0  # for Alignment-Length Synchronous Decoding
    word_seperator: "|"