model:
  _target_: ezspeech.inference_models.tdt_inference.LightningASR
  filepath: ../exported_checkpoint/hehe.ckpt
  device: cuda
  vocab: ezspeech/resource/vocab/vi_en.txt
  decoding_cfg:
    # Using greedy decoding is highly recommended for TDT models. Using greedy-batch will give very bad results
    # if omega is 0; even if omega is non-zero, greedy-batch results are still going to be inaccurate.
    strategy: "malsd_batch"
    model_type: "tdt"
    # this must not be None in order to use the TDT specific decoding method.
    durations: [0,1,2,3,4]
    # greedy strategy config
    greedy:
      max_symbols: 10
    # beam strategy config
    beam:
      beam_size: 2
      ngram_lm_model: /home4/khanhnd/improved_unimatch/corpus/large_corpus.arpa
# for Alignment-Length Synchronous Decoding
# possible_strategies = [
#             "greedy",
#             "greedy_batch",
#             "beam",
#             "alsd",
#             "maes",
#             "malsd_batch",
#         ]